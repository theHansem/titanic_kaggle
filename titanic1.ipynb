{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b8e74d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-19T12:48:56.174088Z",
     "iopub.status.busy": "2022-09-19T12:48:56.172747Z",
     "iopub.status.idle": "2022-09-19T12:48:56.190926Z",
     "shell.execute_reply": "2022-09-19T12:48:56.189522Z"
    },
    "papermill": {
     "duration": 0.028712,
     "end_time": "2022-09-19T12:48:56.193426",
     "exception": false,
     "start_time": "2022-09-19T12:48:56.164714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0cd58e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:48:56.203828Z",
     "iopub.status.busy": "2022-09-19T12:48:56.203385Z",
     "iopub.status.idle": "2022-09-19T12:48:56.263880Z",
     "shell.execute_reply": "2022-09-19T12:48:56.263055Z"
    },
    "papermill": {
     "duration": 0.068616,
     "end_time": "2022-09-19T12:48:56.266217",
     "exception": false,
     "start_time": "2022-09-19T12:48:56.197601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "train_data.set_index('PassengerId', inplace=True)\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "test_data.set_index('PassengerId', inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9160a08b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:48:56.276628Z",
     "iopub.status.busy": "2022-09-19T12:48:56.275777Z",
     "iopub.status.idle": "2022-09-19T12:48:56.293372Z",
     "shell.execute_reply": "2022-09-19T12:48:56.291902Z"
    },
    "papermill": {
     "duration": 0.025293,
     "end_time": "2022-09-19T12:48:56.295945",
     "exception": false,
     "start_time": "2022-09-19T12:48:56.270652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                       \n",
       "892          34.5      0      0   330911   7.8292   NaN        Q  \n",
       "893          47.0      1      0   363272   7.0000   NaN        S  \n",
       "894          62.0      0      0   240276   9.6875   NaN        Q  \n",
       "895          27.0      0      0   315154   8.6625   NaN        S  \n",
       "896          22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe6d137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:48:56.306751Z",
     "iopub.status.busy": "2022-09-19T12:48:56.306417Z",
     "iopub.status.idle": "2022-09-19T12:48:56.331754Z",
     "shell.execute_reply": "2022-09-19T12:48:56.330704Z"
    },
    "papermill": {
     "duration": 0.033671,
     "end_time": "2022-09-19T12:48:56.334137",
     "exception": false,
     "start_time": "2022-09-19T12:48:56.300466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def missing_age(df):\n",
    "    df['Title'] = [re.search(r'(.*\\,\\s)(.*)(\\..*)', name).group(2) for name in df.Name]\n",
    "    mask = (df.Age.isna())\n",
    "    df.loc[mask & (df.Title=='Master'), 'Age'] = 10\n",
    "    df.loc[mask & (df.Title=='Dr'), 'Age'] = 50\n",
    "    df.loc[mask & (df.Title=='Mr'), 'Age'] = 50\n",
    "    df.loc[mask & (df.Title=='Mrs'), 'Age'] = 50\n",
    "    df.loc[mask & (df.Title=='Miss'), 'Age'] = 10\n",
    "    df.loc[mask & (df.Title=='Ms'), 'Age'] = 50\n",
    "    return\n",
    "\n",
    "missing_age(train_data)\n",
    "missing_age(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa9a2da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:48:56.345995Z",
     "iopub.status.busy": "2022-09-19T12:48:56.345535Z",
     "iopub.status.idle": "2022-09-19T12:48:57.496467Z",
     "shell.execute_reply": "2022-09-19T12:48:57.495299Z"
    },
    "papermill": {
     "duration": 1.160152,
     "end_time": "2022-09-19T12:48:57.499060",
     "exception": false,
     "start_time": "2022-09-19T12:48:56.338908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = train_data[\"Survived\"]\n",
    "X_test, X_train, y_test, y_train = train_test_split(train_data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7035242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:48:57.509411Z",
     "iopub.status.busy": "2022-09-19T12:48:57.509067Z",
     "iopub.status.idle": "2022-09-19T12:48:57.531391Z",
     "shell.execute_reply": "2022-09-19T12:48:57.530338Z"
    },
    "papermill": {
     "duration": 0.03016,
     "end_time": "2022-09-19T12:48:57.533778",
     "exception": false,
     "start_time": "2022-09-19T12:48:57.503618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\"]\n",
    "X_train = pd.get_dummies(X_train[features])\n",
    "X_test = pd.get_dummies(X_test[features])\n",
    "test_data = pd.get_dummies(test_data[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4482676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:48:57.544816Z",
     "iopub.status.busy": "2022-09-19T12:48:57.544121Z",
     "iopub.status.idle": "2022-09-19T12:48:57.723235Z",
     "shell.execute_reply": "2022-09-19T12:48:57.722236Z"
    },
    "papermill": {
     "duration": 0.187169,
     "end_time": "2022-09-19T12:48:57.725807",
     "exception": false,
     "start_time": "2022-09-19T12:48:57.538638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(X_test)\n",
    "predict_train = model.predict(X_train)\n",
    "\n",
    "\n",
    "#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "#output.to_csv('submission.csv', index=False)\n",
    "#print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de0f0bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:48:57.736486Z",
     "iopub.status.busy": "2022-09-19T12:48:57.736112Z",
     "iopub.status.idle": "2022-09-19T12:48:57.751033Z",
     "shell.execute_reply": "2022-09-19T12:48:57.749955Z"
    },
    "papermill": {
     "duration": 0.023077,
     "end_time": "2022-09-19T12:48:57.753626",
     "exception": false,
     "start_time": "2022-09-19T12:48:57.730549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[383  93]\n",
      " [ 26 166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.87       476\n",
      "           1       0.64      0.86      0.74       192\n",
      "\n",
      "    accuracy                           0.82       668\n",
      "   macro avg       0.79      0.83      0.80       668\n",
      "weighted avg       0.85      0.82      0.83       668\n",
      "\n",
      "Train set accuracy: 0.874439461883408\n",
      "Test set accuracy: 0.8218562874251497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(predict,y_test))\n",
    "print(classification_report(predict,y_test))\n",
    "print('Train set accuracy: ' + str(accuracy_score(predict_train, y_train)))\n",
    "print('Test set accuracy: ' + str(accuracy_score(predict, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd713ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:48:57.764261Z",
     "iopub.status.busy": "2022-09-19T12:48:57.763855Z",
     "iopub.status.idle": "2022-09-19T12:49:21.364483Z",
     "shell.execute_reply": "2022-09-19T12:49:21.363199Z"
    },
    "papermill": {
     "duration": 23.608787,
     "end_time": "2022-09-19T12:49:21.367050",
     "exception": false,
     "start_time": "2022-09-19T12:48:57.758263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=5, n_estimators=1000, subsample=0.5; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=5, n_estimators=1000, subsample=0.8; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=500, subsample=1; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, n_estimators=1000, subsample=0.8; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=1000, subsample=0.5; total time=   2.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=1000, subsample=0.5; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=1000, subsample=0.1; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=1000, subsample=0.1; total time=   1.2s[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=100, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=500, subsample=1; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=500, subsample=1; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=5, n_estimators=1000, subsample=0.8; total time=   1.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=100, subsample=0.1; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=1000, subsample=0.1; total time=   1.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, n_estimators=1000, subsample=0.5; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=1000, subsample=1; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=1000, subsample=1; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=500, subsample=0.1; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=500, subsample=0.1; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=500, subsample=0.1; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, n_estimators=500, subsample=0.1; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, n_estimators=1000, subsample=0.1; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, n_estimators=1000, subsample=0.1; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, n_estimators=1000, subsample=0.1; total time=   0.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "141 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "141 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\", line 282, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.77117117 0.80276276        nan        nan        nan 0.81159159\n",
      " 0.79831832 0.81603604 0.8160961  0.80720721        nan 0.79357357\n",
      "        nan        nan        nan 0.79357357 0.80720721        nan\n",
      " 0.81165165 0.81159159 0.81603604        nan 0.81177177        nan\n",
      "        nan        nan        nan        nan 0.84306306 0.62780781\n",
      " 0.84306306 0.82066066        nan 0.79807808        nan        nan\n",
      " 0.62780781 0.62780781        nan        nan 0.81135135        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.79807808        nan        nan        nan 0.80708709        nan\n",
      " 0.79363363 0.79831832        nan        nan 0.78012012 0.77159159\n",
      "        nan        nan 0.82510511 0.81159159 0.81615616 0.62780781\n",
      " 0.79369369        nan 0.79381381 0.83843844 0.83387387 0.80714715\n",
      "        nan 0.82054054 0.75807808 0.80708709 0.8160961         nan\n",
      " 0.81615616 0.62780781 0.84750751        nan 0.81147147 0.8160961\n",
      "        nan 0.74456456        nan 0.80258258 0.83411411        nan\n",
      "        nan 0.71753754        nan        nan 0.82510511        nan\n",
      "        nan        nan 0.82492492 0.8384985 ]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['friedman_mse',\n",
       "                                                      'squared_error'],\n",
       "                                        'learning_rate': [0.01, 0.1, 0.5],\n",
       "                                        'loss': ['log_loss', 'exponential'],\n",
       "                                        'max_depth': [1, 3, 5],\n",
       "                                        'n_estimators': [10, 100, 500, 1000],\n",
       "                                        'subsample': [0.1, 0.5, 0.8, 1]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "loss = ['log_loss', 'exponential']\n",
    "learning_rate = [0.01, 0.1, 0.5]\n",
    "n_estimators = [10, 100, 500, 1000]\n",
    "subsample = [0.1, 0.5, 0.8, 1]\n",
    "criterion = ['friedman_mse', 'squared_error']\n",
    "max_depth = [1, 3, 5]\n",
    "\n",
    "random_grid = {'loss': loss,\n",
    "               'learning_rate': learning_rate,\n",
    "               'n_estimators': n_estimators,\n",
    "               'subsample': subsample,\n",
    "               'criterion': criterion,\n",
    "               'max_depth': max_depth}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "model_search = GradientBoostingClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = model_search,\n",
    "                               param_distributions = random_grid, n_iter = 100, cv = 3,\n",
    "                               verbose=2, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67d8d8f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:49:21.381372Z",
     "iopub.status.busy": "2022-09-19T12:49:21.380945Z",
     "iopub.status.idle": "2022-09-19T12:49:21.388814Z",
     "shell.execute_reply": "2022-09-19T12:49:21.387781Z"
    },
    "papermill": {
     "duration": 0.018011,
     "end_time": "2022-09-19T12:49:21.391242",
     "exception": false,
     "start_time": "2022-09-19T12:49:21.373231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1,\n",
       " 'n_estimators': 500,\n",
       " 'max_depth': 3,\n",
       " 'loss': 'exponential',\n",
       " 'learning_rate': 0.01,\n",
       " 'criterion': 'friedman_mse'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74ae7d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:49:21.403962Z",
     "iopub.status.busy": "2022-09-19T12:49:21.403535Z",
     "iopub.status.idle": "2022-09-19T12:49:21.727254Z",
     "shell.execute_reply": "2022-09-19T12:49:21.726148Z"
    },
    "papermill": {
     "duration": 0.333395,
     "end_time": "2022-09-19T12:49:21.730165",
     "exception": false,
     "start_time": "2022-09-19T12:49:21.396770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.812874251497006"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "best_random.fit(X_train, y_train)\n",
    "predict_random = best_random.predict(X_test)\n",
    "random_accuracy = accuracy_score(predict_random, y_test)\n",
    "random_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70f109d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T12:49:21.743777Z",
     "iopub.status.busy": "2022-09-19T12:49:21.743367Z",
     "iopub.status.idle": "2022-09-19T12:49:21.762308Z",
     "shell.execute_reply": "2022-09-19T12:49:21.761181Z"
    },
    "papermill": {
     "duration": 0.029155,
     "end_time": "2022-09-19T12:49:21.765111",
     "exception": false,
     "start_time": "2022-09-19T12:49:21.735956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "predict = best_random.predict(test_data)\n",
    "output = pd.DataFrame({'PassengerId': test_data.index, 'Survived': predict})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a691d",
   "metadata": {
    "papermill": {
     "duration": 0.005711,
     "end_time": "2022-09-19T12:49:21.776421",
     "exception": false,
     "start_time": "2022-09-19T12:49:21.770710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.010959,
   "end_time": "2022-09-19T12:49:24.403698",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-19T12:48:47.392739",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
