{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72720028",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-19T14:03:41.169700Z",
     "iopub.status.busy": "2022-09-19T14:03:41.168746Z",
     "iopub.status.idle": "2022-09-19T14:03:41.183246Z",
     "shell.execute_reply": "2022-09-19T14:03:41.181940Z"
    },
    "papermill": {
     "duration": 0.024063,
     "end_time": "2022-09-19T14:03:41.186452",
     "exception": false,
     "start_time": "2022-09-19T14:03:41.162389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/gender_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b03483a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T14:03:41.196804Z",
     "iopub.status.busy": "2022-09-19T14:03:41.196045Z",
     "iopub.status.idle": "2022-09-19T14:03:41.265805Z",
     "shell.execute_reply": "2022-09-19T14:03:41.264728Z"
    },
    "papermill": {
     "duration": 0.077712,
     "end_time": "2022-09-19T14:03:41.268570",
     "exception": false,
     "start_time": "2022-09-19T14:03:41.190858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "train_data.set_index('PassengerId', inplace=True)\n",
    "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n",
    "test_data.set_index('PassengerId', inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55773f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T14:03:41.278233Z",
     "iopub.status.busy": "2022-09-19T14:03:41.277783Z",
     "iopub.status.idle": "2022-09-19T14:03:41.295443Z",
     "shell.execute_reply": "2022-09-19T14:03:41.294170Z"
    },
    "papermill": {
     "duration": 0.025415,
     "end_time": "2022-09-19T14:03:41.297998",
     "exception": false,
     "start_time": "2022-09-19T14:03:41.272583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                          Name     Sex  \\\n",
       "PassengerId                                                                 \n",
       "892               3                              Kelly, Mr. James    male   \n",
       "893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "894               2                     Myles, Mr. Thomas Francis    male   \n",
       "895               3                              Wirz, Mr. Albert    male   \n",
       "896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                       \n",
       "892          34.5      0      0   330911   7.8292   NaN        Q  \n",
       "893          47.0      1      0   363272   7.0000   NaN        S  \n",
       "894          62.0      0      0   240276   9.6875   NaN        Q  \n",
       "895          27.0      0      0   315154   8.6625   NaN        S  \n",
       "896          22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71edaf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T14:03:41.307987Z",
     "iopub.status.busy": "2022-09-19T14:03:41.307545Z",
     "iopub.status.idle": "2022-09-19T14:03:41.332332Z",
     "shell.execute_reply": "2022-09-19T14:03:41.331173Z"
    },
    "papermill": {
     "duration": 0.033179,
     "end_time": "2022-09-19T14:03:41.335382",
     "exception": false,
     "start_time": "2022-09-19T14:03:41.302203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def missing_age(df):\n",
    "    df['Title'] = [re.search(r'(.*\\,\\s)(.*)(\\..*)', name).group(2) for name in df.Name]\n",
    "    mask = (df.Age.isna())\n",
    "    df.loc[mask & (df.Title=='Master'), 'Age'] = 10\n",
    "    df.loc[mask & (df.Title=='Dr'), 'Age'] = 50\n",
    "    df.loc[mask & (df.Title=='Mr'), 'Age'] = 50\n",
    "    df.loc[mask & (df.Title=='Mrs'), 'Age'] = 50\n",
    "    df.loc[mask & (df.Title=='Miss'), 'Age'] = 10\n",
    "    df.loc[mask & (df.Title=='Ms'), 'Age'] = 50\n",
    "    return\n",
    "\n",
    "missing_age(train_data)\n",
    "missing_age(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe89272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T14:03:41.345376Z",
     "iopub.status.busy": "2022-09-19T14:03:41.344982Z",
     "iopub.status.idle": "2022-09-19T14:03:42.553854Z",
     "shell.execute_reply": "2022-09-19T14:03:42.552521Z"
    },
    "papermill": {
     "duration": 1.217007,
     "end_time": "2022-09-19T14:03:42.556593",
     "exception": false,
     "start_time": "2022-09-19T14:03:41.339586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = train_data[\"Survived\"]\n",
    "X_test, X_train, y_test, y_train = train_test_split(train_data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb6dbd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T14:03:42.566825Z",
     "iopub.status.busy": "2022-09-19T14:03:42.566356Z",
     "iopub.status.idle": "2022-09-19T14:03:42.592306Z",
     "shell.execute_reply": "2022-09-19T14:03:42.591211Z"
    },
    "papermill": {
     "duration": 0.03416,
     "end_time": "2022-09-19T14:03:42.594925",
     "exception": false,
     "start_time": "2022-09-19T14:03:42.560765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\"]\n",
    "X_train = pd.get_dummies(X_train[features])\n",
    "X_test = pd.get_dummies(X_test[features])\n",
    "test_data = pd.get_dummies(test_data[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f766e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T14:03:42.604766Z",
     "iopub.status.busy": "2022-09-19T14:03:42.604352Z",
     "iopub.status.idle": "2022-09-19T14:03:57.558376Z",
     "shell.execute_reply": "2022-09-19T14:03:57.557315Z"
    },
    "papermill": {
     "duration": 14.961854,
     "end_time": "2022-09-19T14:03:57.560870",
     "exception": false,
     "start_time": "2022-09-19T14:03:42.599016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=500, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=500, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=500, subsample=1; total time=   0.3s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, n_estimators=500, subsample=0.1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.4s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.4s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=1000, subsample=0.5; total time=   0.7s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=1000, subsample=0.1; total time=   0.8s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=1000, subsample=0.1; total time=   0.8s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, n_estimators=1000, subsample=0.5; total time=   1.1s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=3, n_estimators=500, subsample=0.1; total time=   0.4s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=1000, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=1000, subsample=1; total time=   0.7s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=1000, subsample=0.5; total time=   0.7s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=1000, subsample=0.5; total time=   0.7s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=1000, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=100, subsample=0.8; total time=   0.1s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=1000, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=3, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.5s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.5s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.4s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.9s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=10, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=500, subsample=0.8; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=5, n_estimators=1000, subsample=1; total time=   1.5s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=500, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=500, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=500, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=1, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.4s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.5, loss=exponential, max_depth=5, n_estimators=500, subsample=0.5; total time=   0.4s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=1, n_estimators=500, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.5, loss=log_loss, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=10, subsample=0.5; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=5, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=10, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=exponential, max_depth=1, n_estimators=1000, subsample=0.1; total time=   0.8s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=10, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=1, n_estimators=10, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=3, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.01, loss=log_loss, max_depth=5, n_estimators=500, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, learning_rate=0.01, loss=exponential, max_depth=3, n_estimators=100, subsample=0.5; total time=   0.1s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, learning_rate=0.01, loss=log_loss, max_depth=3, n_estimators=1000, subsample=1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=100, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=100, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=friedman_mse, learning_rate=0.1, loss=log_loss, max_depth=5, n_estimators=100, subsample=0.1; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=100, subsample=1; total time=   0.1s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, learning_rate=0.5, loss=exponential, max_depth=1, n_estimators=100, subsample=1; total time=   0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "177 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "177 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\", line 282, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.76666667 0.7978979         nan        nan        nan        nan\n",
      "        nan 0.74444444        nan 0.83843844 0.66816817        nan\n",
      " 0.66816817 0.78018018        nan        nan 0.66816817        nan\n",
      "        nan        nan        nan        nan        nan 0.75333333\n",
      " 0.72630631 0.66816817        nan 0.66816817        nan        nan\n",
      "        nan 0.66816817 0.66816817 0.66816817        nan        nan\n",
      "        nan        nan 0.78426426        nan        nan        nan\n",
      "        nan 0.66816817        nan        nan        nan 0.66816817\n",
      " 0.66816817 0.81603604        nan        nan        nan        nan\n",
      " 0.81165165        nan 0.74864865 0.66816817 0.66816817 0.66816817\n",
      "        nan 0.75771772        nan 0.81153153        nan        nan\n",
      " 0.66816817 0.66816817        nan 0.66816817 0.66816817 0.66816817\n",
      "        nan        nan        nan        nan        nan 0.66816817\n",
      "        nan        nan        nan 0.86540541 0.66816817        nan\n",
      " 0.66816817 0.81153153        nan        nan 0.84744745        nan\n",
      "        nan 0.66816817        nan 0.78906907        nan        nan\n",
      "        nan        nan 0.66816817        nan]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'ccp_alpha': [0, 1, 10],\n",
       "                                        'criterion': ['friedman_mse',\n",
       "                                                      'squared_error'],\n",
       "                                        'learning_rate': [0.01, 0.1, 0.5],\n",
       "                                        'loss': ['log_loss', 'exponential'],\n",
       "                                        'max_depth': [1, 3, 5],\n",
       "                                        'n_estimators': [10, 100, 500, 1000],\n",
       "                                        'subsample': [0.1, 0.5, 0.8, 1]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "loss = ['log_loss', 'exponential']\n",
    "learning_rate = [0.01, 0.1, 0.5]\n",
    "n_estimators = [10, 100, 500, 1000]\n",
    "subsample = [0.1, 0.5, 0.8, 1]\n",
    "criterion = ['friedman_mse', 'squared_error']\n",
    "max_depth = [1, 3, 5]\n",
    "ccp_alpha = [0, 1, 10]\n",
    "\n",
    "random_grid = {'loss': loss,\n",
    "               'learning_rate': learning_rate,\n",
    "               'n_estimators': n_estimators,\n",
    "               'subsample': subsample,\n",
    "               'criterion': criterion,\n",
    "               'max_depth': max_depth,\n",
    "               'ccp_alpha': ccp_alpha}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "model_search = GradientBoostingClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = model_search,\n",
    "                               param_distributions = random_grid, n_iter = 100, cv = 3,\n",
    "                               verbose=2, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b11b90dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T14:03:57.574170Z",
     "iopub.status.busy": "2022-09-19T14:03:57.572921Z",
     "iopub.status.idle": "2022-09-19T14:03:57.581115Z",
     "shell.execute_reply": "2022-09-19T14:03:57.580236Z"
    },
    "papermill": {
     "duration": 0.017403,
     "end_time": "2022-09-19T14:03:57.583318",
     "exception": false,
     "start_time": "2022-09-19T14:03:57.565915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1,\n",
       " 'n_estimators': 10,\n",
       " 'max_depth': 3,\n",
       " 'loss': 'exponential',\n",
       " 'learning_rate': 0.1,\n",
       " 'criterion': 'squared_error',\n",
       " 'ccp_alpha': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e93dd6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T14:03:57.595512Z",
     "iopub.status.busy": "2022-09-19T14:03:57.594716Z",
     "iopub.status.idle": "2022-09-19T14:03:57.617399Z",
     "shell.execute_reply": "2022-09-19T14:03:57.616197Z"
    },
    "papermill": {
     "duration": 0.031986,
     "end_time": "2022-09-19T14:03:57.620276",
     "exception": false,
     "start_time": "2022-09-19T14:03:57.588290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 0.8699551569506726\n",
      "Test set accuracy: 0.7754491017964071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "best_random.fit(X_train, y_train)\n",
    "predict_random = best_random.predict(X_test)\n",
    "random_accuracy = accuracy_score(predict_random, y_test)\n",
    "accuracy = accuracy_score(best_random.predict(X_train), y_train)\n",
    "print('Train set accuracy: ' + str(accuracy))\n",
    "print('Test set accuracy: ' + str(random_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "672a305a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-19T14:03:57.632390Z",
     "iopub.status.busy": "2022-09-19T14:03:57.631409Z",
     "iopub.status.idle": "2022-09-19T14:03:57.646291Z",
     "shell.execute_reply": "2022-09-19T14:03:57.644770Z"
    },
    "papermill": {
     "duration": 0.023796,
     "end_time": "2022-09-19T14:03:57.649105",
     "exception": false,
     "start_time": "2022-09-19T14:03:57.625309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "predict = best_random.predict(test_data)\n",
    "output = pd.DataFrame({'PassengerId': test_data.index, 'Survived': predict})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28.761569,
   "end_time": "2022-09-19T14:04:00.276069",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-19T14:03:31.514500",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
